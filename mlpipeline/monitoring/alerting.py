#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Syst√®me de Monitoring et Alertes Quantitatif
Surveillance temps r√©el des performances et d√©tection d'anomalies
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Union, Callable
from pathlib import Path
from datetime import datetime, timedelta
import json
import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart
from dataclasses import dataclass, field
from enum import Enum
import warnings

import requests
from mlpipeline.utils.risk_metrics import comprehensive_metrics

logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore')

class AlertSeverity(Enum):
    """Niveaux de s√©v√©rit√© des alertes"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    EMERGENCY = "emergency"

class AlertChannel(Enum):
    """Canaux de notification"""
    EMAIL = "email"
    DISCORD = "discord"
    TELEGRAM = "telegram"
    SLACK = "slack"
    LOG_ONLY = "log"

@dataclass
class Alert:
    """Structure d'une alerte"""
    
    timestamp: datetime
    title: str
    message: str
    severity: AlertSeverity
    category: str
    metrics: Dict = field(default_factory=dict)
    alert_id: str = field(default_factory=lambda: f"alert_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    def to_dict(self) -> Dict:
        return {
            'alert_id': self.alert_id,
            'timestamp': self.timestamp.isoformat(),
            'title': self.title,
            'message': self.message,
            'severity': self.severity.value,
            'category': self.category,
            'metrics': self.metrics
        }

@dataclass
class MonitoringConfig:
    """Configuration du monitoring"""
    
    # Alertes performances
    max_drawdown_threshold: float = 0.15  # 15%
    min_sharpe_threshold: float = 0.5
    max_vol_threshold: float = 0.4  # 40% annualis√©
    min_return_threshold: float = -0.05  # -5% journalier
    
    # Alertes techniques
    max_correlation_threshold: float = 0.8
    min_diversification_threshold: float = 0.3
    max_position_concentration: float = 0.4
    
    # Alertes donn√©es
    max_missing_data_ratio: float = 0.05  # 5%
    max_data_staleness_hours: int = 2
    min_data_quality_score: float = 0.8
    
    # Notifications
    notification_channels: List[AlertChannel] = field(default_factory=lambda: [AlertChannel.LOG_ONLY])
    email_config: Dict = field(default_factory=dict)
    discord_webhook: Optional[str] = None
    telegram_config: Dict = field(default_factory=dict)
    
    # Fr√©quences monitoring
    check_frequency_minutes: int = 15
    daily_report_time: str = "08:00"
    weekly_report_day: int = 1  # Lundi

class QuantMonitor:
    """
    Syst√®me de monitoring quantitatif avanc√©
    """
    
    def __init__(self, config: MonitoringConfig):
        self.config = config
        
        # √âtat du monitoring
        self.last_check_time = None
        self.alert_history: List[Alert] = []
        self.active_alerts: Dict[str, Alert] = {}
        
        # M√©triques courantes
        self.current_metrics = {}
        self.performance_buffer = []
        self.data_quality_buffer = []
        
        # Seuils adaptatifs
        self.adaptive_thresholds = {}
        
        logger.info("üìä QuantMonitor initialis√©")
    
    def check_system_health(self, 
                          portfolio_data: pd.DataFrame,
                          alpha_performance: Dict[str, Dict],
                          market_data: pd.DataFrame) -> List[Alert]:
        """
        V√©rification compl√®te de la sant√© du syst√®me
        """
        
        alerts = []
        self.last_check_time = datetime.now()
        
        logger.debug("üîç V√©rification sant√© syst√®me...")
        
        try:
            # 1. Performance Portfolio
            perf_alerts = self._check_portfolio_performance(portfolio_data)
            alerts.extend(perf_alerts)
            
            # 2. Performance Alphas
            alpha_alerts = self._check_alpha_performance(alpha_performance)
            alerts.extend(alpha_alerts)
            
            # 3. Qualit√© donn√©es
            data_alerts = self._check_data_quality(market_data)
            alerts.extend(data_alerts)
            
            # 4. Corr√©lations et diversification
            div_alerts = self._check_diversification(alpha_performance)
            alerts.extend(div_alerts)
            
            # 5. D√©tection anomalies
            anomaly_alerts = self._detect_anomalies(portfolio_data, alpha_performance)
            alerts.extend(anomaly_alerts)
            
            # 6. Mise √† jour seuils adaptatifs
            self._update_adaptive_thresholds(portfolio_data, alpha_performance)
            
            # 7. Notification des nouvelles alertes
            self._process_alerts(alerts)
            
            logger.info(f"üìä Check termin√©: {len(alerts)} alertes g√©n√©r√©es")
            
        except Exception as e:
            error_alert = Alert(
                timestamp=datetime.now(),
                title="Erreur Monitoring",
                message=f"Erreur lors du check syst√®me: {e}",
                severity=AlertSeverity.CRITICAL,
                category="system"
            )
            alerts.append(error_alert)
            logger.error(f"‚ùå Erreur monitoring: {e}")
        
        return alerts
    
    def _check_portfolio_performance(self, portfolio_data: pd.DataFrame) -> List[Alert]:
        """V√©rification performance du portfolio"""
        
        alerts = []
        
        if portfolio_data.empty or len(portfolio_data) < 2:
            return alerts
        
        try:
            # Calcul m√©triques r√©centes
            returns = portfolio_data['value'].pct_change().dropna()
            
            if len(returns) == 0:
                return alerts
            
            # M√©triques actuelles
            current_metrics = comprehensive_metrics(returns.values[-252:])  # 1 an
            
            # 1. Drawdown excessif
            max_dd = current_metrics.get('max_drawdown', 0)
            if max_dd > self.config.max_drawdown_threshold:
                alerts.append(Alert(
                    timestamp=datetime.now(),
                    title="Drawdown Critique",
                    message=f"Max drawdown: {max_dd:.2%} > seuil {self.config.max_drawdown_threshold:.2%}",
                    severity=AlertSeverity.CRITICAL,
                    category="performance",
                    metrics={'max_drawdown': max_dd, 'threshold': self.config.max_drawdown_threshold}
                ))
            
            # 2. Sharpe ratio faible
            sharpe = current_metrics.get('sharpe_ratio', 0)
            if sharpe < self.config.min_sharpe_threshold:
                alerts.append(Alert(
                    timestamp=datetime.now(),
                    title="Sharpe Ratio Faible",
                    message=f"Sharpe ratio: {sharpe:.3f} < seuil {self.config.min_sharpe_threshold:.3f}",
                    severity=AlertSeverity.WARNING,
                    category="performance",
                    metrics={'sharpe_ratio': sharpe, 'threshold': self.config.min_sharpe_threshold}
                ))
            
            # 3. Volatilit√© excessive
            volatility = returns.std() * np.sqrt(252)  # Annualis√©e
            if volatility > self.config.max_vol_threshold:
                alerts.append(Alert(
                    timestamp=datetime.now(),
                    title="Volatilit√© Excessive",
                    message=f"Volatilit√©: {volatility:.2%} > seuil {self.config.max_vol_threshold:.2%}",
                    severity=AlertSeverity.WARNING,
                    category="risk",
                    metrics={'volatility': volatility, 'threshold': self.config.max_vol_threshold}
                ))
            
            # 4. Return journalier critique
            if len(returns) > 0:
                last_return = returns.iloc[-1]
                if last_return < self.config.min_return_threshold:
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title="Return Journalier Critique",
                        message=f"Return: {last_return:.2%} < seuil {self.config.min_return_threshold:.2%}",
                        severity=AlertSeverity.CRITICAL,
                        category="performance",
                        metrics={'daily_return': last_return, 'threshold': self.config.min_return_threshold}
                    ))
            
        except Exception as e:
            logger.error(f"‚ùå Erreur check performance: {e}")
        
        return alerts
    
    def _check_alpha_performance(self, alpha_performance: Dict[str, Dict]) -> List[Alert]:
        """V√©rification performance individuelle des alphas"""
        
        alerts = []
        
        try:
            for alpha_name, metrics in alpha_performance.items():
                
                # 1. Performance d√©grad√©e
                sharpe = metrics.get('sharpe_ratio', 0)
                if sharpe < 0:
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title=f"Alpha {alpha_name} D√©faillant",
                        message=f"{alpha_name}: Sharpe ratio n√©gatif ({sharpe:.3f})",
                        severity=AlertSeverity.WARNING,
                        category="alpha_performance",
                        metrics={'alpha': alpha_name, 'sharpe': sharpe}
                    ))
                
                # 2. Corr√©lation trop forte avec march√©
                market_corr = metrics.get('market_correlation', 0)
                if abs(market_corr) > 0.9:
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title=f"Alpha {alpha_name} Trop Corr√©l√©",
                        message=f"{alpha_name}: Corr√©lation march√© {market_corr:.3f}",
                        severity=AlertSeverity.WARNING,
                        category="diversification",
                        metrics={'alpha': alpha_name, 'correlation': market_corr}
                    ))
                
                # 3. Absence de signaux
                signals_count = metrics.get('signals_generated', 0)
                if signals_count == 0:
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title=f"Alpha {alpha_name} Inactif",
                        message=f"{alpha_name}: Aucun signal g√©n√©r√© r√©cemment",
                        severity=AlertSeverity.WARNING,
                        category="alpha_activity",
                        metrics={'alpha': alpha_name, 'signals_count': signals_count}
                    ))
        
        except Exception as e:
            logger.error(f"‚ùå Erreur check alphas: {e}")
        
        return alerts
    
    def _check_data_quality(self, market_data: pd.DataFrame) -> List[Alert]:
        """V√©rification qualit√© des donn√©es"""
        
        alerts = []
        
        try:
            if market_data.empty:
                alerts.append(Alert(
                    timestamp=datetime.now(),
                    title="Donn√©es Manquantes",
                    message="Aucune donn√©e de march√© disponible",
                    severity=AlertSeverity.EMERGENCY,
                    category="data_quality"
                ))
                return alerts
            
            # 1. Donn√©es manquantes
            missing_ratio = market_data.isnull().sum().sum() / (len(market_data) * len(market_data.columns))
            if missing_ratio > self.config.max_missing_data_ratio:
                alerts.append(Alert(
                    timestamp=datetime.now(),
                    title="Donn√©es Incompl√®tes",
                    message=f"Ratio donn√©es manquantes: {missing_ratio:.2%}",
                    severity=AlertSeverity.WARNING,
                    category="data_quality",
                    metrics={'missing_ratio': missing_ratio}
                ))
            
            # 2. Fra√Æcheur des donn√©es
            if hasattr(market_data.index, 'max'):
                last_data_time = market_data.index.max()
                if isinstance(last_data_time, pd.Timestamp):
                    staleness_hours = (datetime.now(last_data_time.tz) - last_data_time).total_seconds() / 3600
                    
                    if staleness_hours > self.config.max_data_staleness_hours:
                        alerts.append(Alert(
                            timestamp=datetime.now(),
                            title="Donn√©es P√©rim√©es",
                            message=f"Derni√®res donn√©es: {staleness_hours:.1f}h",
                            severity=AlertSeverity.CRITICAL,
                            category="data_quality",
                            metrics={'staleness_hours': staleness_hours}
                        ))
            
            # 3. Prix suspects (variations extr√™mes)
            if 'close' in market_data.columns:
                price_changes = market_data['close'].pct_change().dropna()
                extreme_changes = price_changes[abs(price_changes) > 0.2]  # >20%
                
                if len(extreme_changes) > 0:
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title="Prix Suspects D√©tect√©s",
                        message=f"{len(extreme_changes)} variations >20% d√©tect√©es",
                        severity=AlertSeverity.WARNING,
                        category="data_quality",
                        metrics={'extreme_changes_count': len(extreme_changes)}
                    ))
        
        except Exception as e:
            logger.error(f"‚ùå Erreur check donn√©es: {e}")
        
        return alerts
    
    def _check_diversification(self, alpha_performance: Dict[str, Dict]) -> List[Alert]:
        """V√©rification diversification du portfolio"""
        
        alerts = []
        
        try:
            if len(alpha_performance) < 2:
                return alerts
            
            # Calcul matrice corr√©lations
            correlations = []
            alpha_names = list(alpha_performance.keys())
            
            for i, alpha1 in enumerate(alpha_names):
                for j, alpha2 in enumerate(alpha_names[i+1:], i+1):
                    corr = alpha_performance[alpha1].get('correlation_with', {}).get(alpha2, 0)
                    correlations.append(abs(corr))
            
            # Corr√©lation moyenne
            if correlations:
                avg_correlation = np.mean(correlations)
                max_correlation = np.max(correlations)
                
                # Alerte corr√©lation excessive
                if max_correlation > self.config.max_correlation_threshold:
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title="Corr√©lation Excessive Entre Alphas",
                        message=f"Max corr√©lation: {max_correlation:.3f}",
                        severity=AlertSeverity.WARNING,
                        category="diversification",
                        metrics={'max_correlation': max_correlation, 'avg_correlation': avg_correlation}
                    ))
        
        except Exception as e:
            logger.error(f"‚ùå Erreur check diversification: {e}")
        
        return alerts
    
    def _detect_anomalies(self, portfolio_data: pd.DataFrame, alpha_performance: Dict) -> List[Alert]:
        """D√©tection d'anomalies par ML/statistiques"""
        
        alerts = []
        
        try:
            if portfolio_data.empty or len(portfolio_data) < 50:
                return alerts
            
            returns = portfolio_data['value'].pct_change().dropna()
            
            # 1. D√©tection outliers (Z-score)
            z_scores = np.abs((returns - returns.mean()) / returns.std())
            outliers = z_scores > 3
            
            if outliers.sum() > len(returns) * 0.05:  # >5% outliers
                alerts.append(Alert(
                    timestamp=datetime.now(),
                    title="Outliers D√©tect√©s",
                    message=f"{outliers.sum()} returns outliers ({outliers.sum()/len(returns):.1%})",
                    severity=AlertSeverity.WARNING,
                    category="anomaly",
                    metrics={'outliers_count': int(outliers.sum()), 'outliers_ratio': float(outliers.sum()/len(returns))}
                ))
            
            # 2. Changement de r√©gime (variance)
            if len(returns) > 100:
                recent_vol = returns.iloc[-30:].std()
                historical_vol = returns.iloc[-100:-30].std()
                vol_ratio = recent_vol / historical_vol
                
                if vol_ratio > 2.0:  # Volatilit√© doubl√©e
                    alerts.append(Alert(
                        timestamp=datetime.now(),
                        title="Changement R√©gime Volatilit√©",
                        message=f"Volatilit√© r√©cente x{vol_ratio:.1f}",
                        severity=AlertSeverity.WARNING,
                        category="regime_change",
                        metrics={'volatility_ratio': vol_ratio}
                    ))
        
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©tection anomalies: {e}")
        
        return alerts
    
    def _update_adaptive_thresholds(self, portfolio_data: pd.DataFrame, alpha_performance: Dict):
        """Mise √† jour seuils adaptatifs"""
        
        try:
            if portfolio_data.empty:
                return
            
            returns = portfolio_data['value'].pct_change().dropna()
            
            if len(returns) > 100:
                # Seuil drawdown adaptatif (95e percentile historique)
                historical_dds = []
                for i in range(50, len(returns)):
                    period_returns = returns.iloc[i-50:i]
                    period_dd = (period_returns.cumsum().cummax() - period_returns.cumsum()).max()
                    historical_dds.append(period_dd)
                
                if historical_dds:
                    adaptive_dd_threshold = np.percentile(historical_dds, 95)
                    self.adaptive_thresholds['max_drawdown'] = adaptive_dd_threshold
                    
                    logger.debug(f"Seuil DD adaptatif: {adaptive_dd_threshold:.2%}")
        
        except Exception as e:
            logger.error(f"‚ùå Erreur seuils adaptatifs: {e}")
    
    def _process_alerts(self, alerts: List[Alert]):
        """Traitement et notification des alertes"""
        
        new_alerts = []
        
        for alert in alerts:
            # √âviter doublons r√©cents
            if not self._is_duplicate_alert(alert):
                new_alerts.append(alert)
                self.alert_history.append(alert)
                self.active_alerts[alert.category] = alert
        
        # Notification
        if new_alerts:
            self._send_notifications(new_alerts)
            logger.info(f"üì¢ {len(new_alerts)} nouvelles alertes envoy√©es")
    
    def _is_duplicate_alert(self, alert: Alert) -> bool:
        """V√©rification doublons d'alertes"""
        
        # Chercher alertes similaires dans les 30 derni√®res minutes
        cutoff_time = datetime.now() - timedelta(minutes=30)
        
        for existing_alert in reversed(self.alert_history[-50:]):  # Check 50 derni√®res
            if (existing_alert.timestamp > cutoff_time and
                existing_alert.category == alert.category and
                existing_alert.title == alert.title):
                return True
        
        return False
    
    def _send_notifications(self, alerts: List[Alert]):
        """Envoi notifications multi-canal"""
        
        for channel in self.config.notification_channels:
            try:
                if channel == AlertChannel.EMAIL:
                    self._send_email_alerts(alerts)
                elif channel == AlertChannel.DISCORD:
                    self._send_discord_alerts(alerts)
                elif channel == AlertChannel.TELEGRAM:
                    self._send_telegram_alerts(alerts)
                elif channel == AlertChannel.LOG_ONLY:
                    self._log_alerts(alerts)
                    
            except Exception as e:
                logger.error(f"‚ùå Erreur notification {channel.value}: {e}")
    
    def _send_email_alerts(self, alerts: List[Alert]):
        """Envoi alertes par email"""
        
        if not self.config.email_config:
            return
        
        try:
            smtp_server = self.config.email_config.get('smtp_server')
            smtp_port = self.config.email_config.get('smtp_port', 587)
            username = self.config.email_config.get('username')
            password = self.config.email_config.get('password')
            to_addresses = self.config.email_config.get('to_addresses', [])
            
            if not all([smtp_server, username, password, to_addresses]):
                return
            
            # Composition email
            subject = f"[QuantBot] {len(alerts)} Alertes - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            
            body_html = self._format_alerts_email(alerts)
            
            msg = MimeMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = username
            msg['To'] = ', '.join(to_addresses)
            
            html_part = MimeText(body_html, 'html')
            msg.attach(html_part)
            
            # Envoi
            with smtplib.SMTP(smtp_server, smtp_port) as server:
                server.starttls()
                server.login(username, password)
                server.send_message(msg)
            
            logger.debug("üìß Email alertes envoy√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur email: {e}")
    
    def _send_discord_alerts(self, alerts: List[Alert]):
        """Envoi alertes Discord via webhook"""
        
        if not self.config.discord_webhook:
            return
        
        try:
            for alert in alerts:
                embed = {
                    "title": alert.title,
                    "description": alert.message,
                    "color": self._get_color_for_severity(alert.severity),
                    "timestamp": alert.timestamp.isoformat(),
                    "fields": [
                        {"name": "Cat√©gorie", "value": alert.category, "inline": True},
                        {"name": "S√©v√©rit√©", "value": alert.severity.value.upper(), "inline": True}
                    ]
                }
                
                if alert.metrics:
                    metrics_str = "\\n".join([f"{k}: {v}" for k, v in alert.metrics.items()])
                    embed["fields"].append({"name": "M√©triques", "value": f"```{metrics_str}```"})
                
                payload = {"embeds": [embed]}
                
                response = requests.post(self.config.discord_webhook, json=payload)
                response.raise_for_status()
            
            logger.debug("üí¨ Discord alertes envoy√©es")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Discord: {e}")
    
    def _send_telegram_alerts(self, alerts: List[Alert]):
        """Envoi alertes Telegram"""
        
        if not self.config.telegram_config:
            return
        
        try:
            bot_token = self.config.telegram_config.get('bot_token')
            chat_id = self.config.telegram_config.get('chat_id')
            
            if not bot_token or not chat_id:
                return
            
            for alert in alerts:
                message = f"ü§ñ *{alert.title}*\\n\\n{alert.message}\\n\\n_S√©v√©rit√©: {alert.severity.value}_"
                
                url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
                payload = {
                    'chat_id': chat_id,
                    'text': message,
                    'parse_mode': 'Markdown'
                }
                
                response = requests.post(url, json=payload)
                response.raise_for_status()
            
            logger.debug("üì± Telegram alertes envoy√©es")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Telegram: {e}")
    
    def _log_alerts(self, alerts: List[Alert]):
        """Log des alertes"""
        
        for alert in alerts:
            level = {
                AlertSeverity.INFO: logging.INFO,
                AlertSeverity.WARNING: logging.WARNING,
                AlertSeverity.CRITICAL: logging.ERROR,
                AlertSeverity.EMERGENCY: logging.CRITICAL
            }.get(alert.severity, logging.INFO)
            
            logger.log(level, f"üö® {alert.title}: {alert.message}")
    
    def _format_alerts_email(self, alerts: List[Alert]) -> str:
        """Formatage HTML pour email"""
        
        html = f"""
        <html>
        <head>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .alert {{ border-left: 4px solid; padding: 10px; margin: 10px 0; }}
                .critical {{ border-color: #dc3545; background: #f8d7da; }}
                .warning {{ border-color: #ffc107; background: #fff3cd; }}
                .info {{ border-color: #17a2b8; background: #d1ecf1; }}
                .metrics {{ background: #f8f9fa; padding: 8px; font-family: monospace; }}
            </style>
        </head>
        <body>
            <h2>Alertes Syst√®me Quantitatif - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</h2>
        """
        
        for alert in alerts:
            css_class = alert.severity.value
            html += f"""
            <div class="alert {css_class}">
                <h3>{alert.title}</h3>
                <p>{alert.message}</p>
                <small>Cat√©gorie: {alert.category} | S√©v√©rit√©: {alert.severity.value.upper()}</small>
                """
            
            if alert.metrics:
                html += '<div class="metrics">'
                for key, value in alert.metrics.items():
                    html += f"{key}: {value}<br>"
                html += '</div>'
            
            html += '</div>'
        
        html += """
        </body>
        </html>
        """
        
        return html
    
    def _get_color_for_severity(self, severity: AlertSeverity) -> int:
        """Couleur Discord par s√©v√©rit√©"""
        
        colors = {
            AlertSeverity.INFO: 0x17a2b8,      # Bleu
            AlertSeverity.WARNING: 0xffc107,   # Jaune
            AlertSeverity.CRITICAL: 0xdc3545,  # Rouge
            AlertSeverity.EMERGENCY: 0x6f42c1  # Violet
        }
        
        return colors.get(severity, 0x17a2b8)
    
    def generate_daily_report(self, portfolio_data: pd.DataFrame, 
                            alpha_performance: Dict) -> Dict:
        """G√©n√©ration rapport journalier"""
        
        report = {
            'date': datetime.now().date(),
            'portfolio_summary': {},
            'alpha_summary': {},
            'alerts_summary': {},
            'recommendations': []
        }
        
        try:
            # Portfolio summary
            if not portfolio_data.empty:
                returns = portfolio_data['value'].pct_change().dropna()
                if len(returns) > 0:
                    report['portfolio_summary'] = {
                        'total_return_1d': returns.iloc[-1] if len(returns) >= 1 else 0,
                        'total_return_7d': returns.iloc[-7:].sum() if len(returns) >= 7 else 0,
                        'volatility_7d': returns.iloc[-7:].std() * np.sqrt(7) if len(returns) >= 7 else 0,
                        'sharpe_30d': (returns.iloc[-30:].mean() / returns.iloc[-30:].std()) * np.sqrt(30) if len(returns) >= 30 else 0
                    }
            
            # Alerts summary
            recent_alerts = [a for a in self.alert_history if a.timestamp.date() == datetime.now().date()]
            report['alerts_summary'] = {
                'total_alerts': len(recent_alerts),
                'critical_alerts': len([a for a in recent_alerts if a.severity == AlertSeverity.CRITICAL]),
                'warning_alerts': len([a for a in recent_alerts if a.severity == AlertSeverity.WARNING]),
                'categories': list(set([a.category for a in recent_alerts]))
            }
            
            # Recommandations
            if report['alerts_summary']['critical_alerts'] > 0:
                report['recommendations'].append("V√©rifier alertes critiques et ajuster positions si n√©cessaire")
            
            if report['portfolio_summary'].get('volatility_7d', 0) > 0.3:
                report['recommendations'].append("Volatilit√© √©lev√©e - consid√©rer r√©duction exposition")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration rapport: {e}")
        
        return report
    
    def get_alert_history(self, days: int = 7) -> pd.DataFrame:
        """Historique des alertes"""
        
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_alerts = [a for a in self.alert_history if a.timestamp > cutoff_date]
        
        if not recent_alerts:
            return pd.DataFrame()
        
        data = []
        for alert in recent_alerts:
            data.append({
                'timestamp': alert.timestamp,
                'title': alert.title,
                'message': alert.message,
                'severity': alert.severity.value,
                'category': alert.category,
                'alert_id': alert.alert_id
            })
        
        df = pd.DataFrame(data)
        df.set_index('timestamp', inplace=True)
        df.sort_index(inplace=True)
        
        return df


# ==============================================
# FONCTIONS UTILITAIRES
# ==============================================

def create_monitoring_config(config_dict: Dict) -> MonitoringConfig:
    """Cr√©ation configuration depuis dictionnaire"""
    
    config = MonitoringConfig()
    
    for key, value in config_dict.items():
        if hasattr(config, key):
            setattr(config, key, value)
    
    return config


def run_monitoring_check(portfolio_data: pd.DataFrame,
                        alpha_performance: Dict,
                        market_data: pd.DataFrame,
                        config: Optional[MonitoringConfig] = None) -> List[Alert]:
    """
    Interface simplifi√©e pour check monitoring
    """
    
    if config is None:
        config = MonitoringConfig()
    
    monitor = QuantMonitor(config)
    return monitor.check_system_health(portfolio_data, alpha_performance, market_data)