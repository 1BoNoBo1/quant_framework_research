#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
R√©cup√©ration de donn√©es crypto en temps r√©el
Am√©lioration du data_ingest.py original avec vraies donn√©es
"""

import asyncio
import logging
import os
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import ccxt
import pandas as pd
import numpy as np
from binance.client import Client
from binance.exceptions import BinanceAPIException
import yaml
from pathlib import Path

# Ajouter le cache syst√®me
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
try:
    from orchestration.smart_cache import cached_data, get_cache
except ImportError:
    logger.warning("Smart cache non disponible - fonctionnement normal")
    # D√©corateur vide si cache non disponible
    def cached_data(ttl_hours=1, key_args=None):
        def decorator(func):
            return func
        return decorator

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CryptoDataFetcher:
    """R√©cup√©rateur de donn√©es crypto multi-sources"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        self.config = self._load_config(config_path)
        self.binance_client = None
        self.ccxt_exchange = None
        self._setup_clients()
        
    def _load_config(self, config_path: str) -> Dict:
        """Charge la configuration"""
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    return yaml.safe_load(f)
            else:
                # Configuration par d√©faut
                return {
                    "symbols": ["BTCUSDT", "ETHUSDT", "BNBUSDT"],
                    "timeframes": ["1h", "4h", "1d"],
                    "lookback_days": 365,
                    "data_dir": "data/raw"
                }
        except Exception as e:
            logger.error(f"Erreur chargement config: {e}")
            return {}
    
    def _setup_clients(self):
        """Configure les clients API"""
        try:
            # Binance API (optionnel avec cl√©s)
            api_key = os.getenv('BINANCE_API_KEY', '')
            api_secret = os.getenv('BINANCE_API_SECRET', '')
            
            if api_key and api_secret:
                self.binance_client = Client(api_key, api_secret)
                logger.info("‚úÖ Client Binance configur√© avec API keys")
            else:
                logger.info("‚ö†Ô∏è  Pas de cl√©s Binance - donn√©es publiques uniquement")
            
            # CCXT pour donn√©es publiques
            self.ccxt_exchange = ccxt.binance({
                'rateLimit': 1200,
                'enableRateLimit': True,
            })
            logger.info("‚úÖ Client CCXT configur√©")
            
        except Exception as e:
            logger.error(f"Erreur configuration clients: {e}")
    
    @cached_data(ttl_hours=1, key_args=['symbol', 'timeframe', 'limit'])
    async def fetch_ohlcv(self, 
                         symbol: str, 
                         timeframe: str = '1h', 
                         limit: int = 1000) -> pd.DataFrame:
        """
        R√©cup√®re donn√©es OHLCV via CCXT
        
        Args:
            symbol: Paire crypto (ex: 'BTC/USDT')
            timeframe: Intervalle de temps
            limit: Nombre de bougies
        """
        try:
            # Normaliser le symbole pour CCXT
            if '/' not in symbol:
                # BTCUSDT -> BTC/USDT
                if symbol.endswith('USDT'):
                    base = symbol[:-4]
                    quote = 'USDT'
                    ccxt_symbol = f"{base}/{quote}"
                else:
                    ccxt_symbol = symbol
            else:
                ccxt_symbol = symbol
            
            logger.info(f"üìä R√©cup√©ration {ccxt_symbol} {timeframe} (limit={limit})")
            
            # R√©cup√©ration via CCXT
            ohlcv_data = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.ccxt_exchange.fetch_ohlcv(
                    ccxt_symbol, timeframe, limit=limit
                )
            )
            
            # Conversion en DataFrame
            df = pd.DataFrame(ohlcv_data, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume'
            ])
            
            # Conversion timestamp
            df['time'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            df = df.drop('timestamp', axis=1)
            
            # R√©organisation colonnes
            df = df[['time', 'open', 'high', 'low', 'close', 'volume']]
            
            logger.info(f"‚úÖ {len(df)} bougies r√©cup√©r√©es pour {ccxt_symbol}")
            return df
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration {symbol}: {e}")
            return pd.DataFrame()
    
    async def fetch_historical_bulk(self, 
                                   symbols: List[str], 
                                   timeframes: List[str],
                                   days: int = 365) -> Dict[str, pd.DataFrame]:
        """
        R√©cup√©ration en masse des donn√©es historiques
        """
        results = {}
        
        for symbol in symbols:
            for timeframe in timeframes:
                try:
                    # Calcul du nombre de bougies n√©cessaires
                    if timeframe == '1h':
                        limit = min(days * 24, 1000)
                    elif timeframe == '4h':
                        limit = min(days * 6, 1000)
                    elif timeframe == '1d':
                        limit = min(days, 1000)
                    else:
                        limit = 1000
                    
                    # R√©cup√©ration asynchrone
                    df = await self.fetch_ohlcv(symbol, timeframe, limit)
                    
                    if not df.empty:
                        key = f"{symbol}_{timeframe}"
                        results[key] = df
                        
                        # Sauvegarde
                        self._save_to_parquet(df, symbol, timeframe)
                    
                    # Pause pour √©viter rate limit
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"Erreur {symbol} {timeframe}: {e}")
                    continue
        
        return results
    
    def _save_to_parquet(self, df: pd.DataFrame, symbol: str, timeframe: str):
        """Sauvegarde en format Parquet"""
        try:
            data_dir = Path(self.config.get('data_dir', 'data/raw'))
            data_dir.mkdir(parents=True, exist_ok=True)
            
            # Nom de fichier compatible avec l'original
            filename = f"ohlcv_{symbol.replace('/', '')}_{timeframe}.parquet"
            filepath = data_dir / filename
            
            df.to_parquet(filepath, index=False)
            logger.info(f"üíæ Sauvegard√©: {filepath}")
            
        except Exception as e:
            logger.error(f"Erreur sauvegarde {symbol}: {e}")
    
    def validate_data(self, df: pd.DataFrame, symbol: str) -> bool:
        """Validation des donn√©es"""
        if df.empty:
            logger.warning(f"‚ö†Ô∏è  DataFrame vide pour {symbol}")
            return False
        
        # V√©rifications de base
        required_cols = ['time', 'open', 'high', 'low', 'close', 'volume']
        if not all(col in df.columns for col in required_cols):
            logger.error(f"‚ùå Colonnes manquantes pour {symbol}")
            return False
        
        # V√©rifications logiques OHLCV
        invalid_ohlc = (
            (df['high'] < df['low']) |
            (df['high'] < df['open']) |
            (df['high'] < df['close']) |
            (df['low'] > df['open']) |
            (df['low'] > df['close'])
        ).sum()
        
        if invalid_ohlc > 0:
            logger.warning(f"‚ö†Ô∏è  {invalid_ohlc} bougies OHLC invalides pour {symbol}")
        
        # V√©rification volumes n√©gatifs
        negative_volume = (df['volume'] < 0).sum()
        if negative_volume > 0:
            logger.warning(f"‚ö†Ô∏è  {negative_volume} volumes n√©gatifs pour {symbol}")
        
        logger.info(f"‚úÖ Validation {symbol}: {len(df)} bougies valides")
        return True
    
    def get_realtime_price(self, symbol: str) -> Optional[float]:
        """Prix en temps r√©el"""
        try:
            ticker = self.ccxt_exchange.fetch_ticker(symbol)
            return float(ticker['last'])
        except Exception as e:
            logger.error(f"Erreur prix temps r√©el {symbol}: {e}")
            return None

# ==============================================
# FONCTIONS UTILITAIRES
# ==============================================

def validate_real_data_only(df: pd.DataFrame, symbol: str, source: str = "API") -> bool:
    """
    Validation stricte : UNIQUEMENT donn√©es r√©elles accept√©es
    Refuse tout data synth√©tique ou suspect
    """
    if df.empty:
        logger.error(f"‚ùå REJET√â {symbol}: DataFrame vide")
        return False
    
    # V√©rification m√©tadonn√©es (pas de patterns synth√©tiques)
    if 'synthetic' in str(df.attrs) or source == "synthetic":
        logger.error(f"‚ùå REJET√â {symbol}: Donn√©es synth√©tiques d√©tect√©es")
        return False
    
    # V√©rification timestamps r√©alistes (pas trop r√©guliers)
    if len(df) > 10:
        time_diffs = df['time'].diff().dropna()
        if time_diffs.nunique() == 1:  # Trop r√©gulier = synth√©tique
            logger.warning(f"‚ö†Ô∏è  SUSPECT {symbol}: Timestamps trop r√©guliers")
    
    # V√©rification prix coh√©rents avec le march√©
    if 'close' in df.columns:
        close_prices = df['close']
        if (close_prices == close_prices.iloc[0]).all():  # Prix constant = synth√©tique
            logger.error(f"‚ùå REJET√â {symbol}: Prix constants d√©tect√©s")
            return False
    
    # Validation volumes r√©alistes
    if 'volume' in df.columns:
        volumes = df['volume']
        if (volumes < 0).any():
            logger.error(f"‚ùå REJET√â {symbol}: Volumes n√©gatifs")
            return False
        
        # Volume trop constant = suspect
        if volumes.std() / volumes.mean() < 0.1:
            logger.warning(f"‚ö†Ô∏è  SUSPECT {symbol}: Volumes trop constants")
    
    logger.info(f"‚úÖ VALID√â {symbol}: {len(df)} bougies r√©elles")
    return True

# ==============================================
# SCRIPT PRINCIPAL
# ==============================================

async def main():
    """Script principal de r√©cup√©ration de donn√©es"""
    import argparse
    
    parser = argparse.ArgumentParser(description="R√©cup√©ration donn√©es crypto")
    parser.add_argument("--symbols", nargs="+", default=["BTC/USDT", "ETH/USDT"])
    parser.add_argument("--timeframes", nargs="+", default=["1h"])
    parser.add_argument("--days", type=int, default=365)
    parser.add_argument("--synthetic", action="store_true", 
                       help="Utiliser donn√©es synth√©tiques")
    
    args = parser.parse_args()
    
    fetcher = CryptoDataFetcher()
    
    # UNIQUEMENT donn√©es r√©elles - pas de mode synth√©tique
    logger.info("üìä Mode donn√©es r√©elles UNIQUEMENT")
    results = await fetcher.fetch_historical_bulk(
        args.symbols, args.timeframes, args.days
    )
    
    if not results:
        logger.error("‚ùå √âCHEC: Aucune donn√©e r√©elle r√©cup√©r√©e")
        logger.error("üí° V√©rifiez votre connexion internet et les APIs crypto")
        sys.exit(1)
    
    logger.info(f"‚úÖ R√©cup√©ration termin√©e: {len(results)} datasets")
    
    # Statistiques
    for key, df in results.items():
        if not df.empty:
            logger.info(f"üìà {key}: {len(df)} bougies, "
                      f"{df['time'].min()} -> {df['time'].max()}")

if __name__ == "__main__":
    asyncio.run(main())