# ğŸ”¬ Research Platform Overview

Infrastructure distribuÃ©e de recherche quantitative avec Data Lake, computing distribuÃ© et MLOps.

## Architecture Research Platform

```
QFrame Research Platform
â”œâ”€â”€ ğŸ—ï¸ QFrame Core (validÃ© 100%)
â”‚   â”œâ”€â”€ Container DI + Configuration Pydantic
â”‚   â”œâ”€â”€ StratÃ©gies : DMN LSTM, Mean Reversion, RL Alpha
â”‚   â”œâ”€â”€ Feature Engineering : 18+ opÃ©rateurs symboliques
â”‚   â””â”€â”€ Services : Backtesting, Portfolio, Risk
â”œâ”€â”€ ğŸ”¬ Research Layer (6/8 validÃ©)
â”‚   â”œâ”€â”€ âœ… Data Lake Storage (S3/MinIO/Local)
â”‚   â”œâ”€â”€ âœ… Data Catalog + Feature Store
â”‚   â”œâ”€â”€ âœ… Distributed Backtesting (Dask/Ray)
â”‚   â”œâ”€â”€ âœ… Integration Layer QFrame â†” Research
â”‚   â”œâ”€â”€ âœ… Advanced Performance Analytics
â”‚   â””â”€â”€ âš ï¸ SDK Modules (en dÃ©veloppement)
â””â”€â”€ ğŸ³ Infrastructure Docker (validÃ© 100%)
```

## Composants OpÃ©rationnels

### Data Lake Infrastructure
```python
from qframe.research.data_lake import DataLakeStorage, FeatureStore

# Multi-backend storage avec fallback
storage = LocalFileStorage("/data/lake")  # ou S3Storage, MinIOStorage
feature_store = FeatureStore(storage)
catalog = DataCatalog(db_url="postgresql://...")
```

### Distributed Backtesting
```python
from qframe.research.backtesting import DistributedBacktestEngine

engine = DistributedBacktestEngine(
    compute_backend="dask",  # ou "ray", "sequential"
    max_workers=4
)

# Backtesting multi-stratÃ©gies distribuÃ©
results = await engine.run_distributed_backtest(
    strategies=["adaptive_mean_reversion", "dmn_lstm"],
    datasets=[data1, data2],
    parameter_grids={"lookback": [10, 20, 30]},
    n_splits=5
)
```

## Docker Research Stack

### Services DÃ©ployÃ©s
- âœ… **JupyterHub** : Multi-user research environment
- âœ… **MLflow** : Experiment tracking avec PostgreSQL + S3
- âœ… **Dask Cluster** : Distributed computing
- âœ… **Ray Cluster** : Distributed ML
- âœ… **TimescaleDB** : Time-series data storage
- âœ… **MinIO** : S3-compatible object storage
- âœ… **Elasticsearch** : Search et analytics
- âœ… **Superset** : Data visualization

### DÃ©marrage
```bash
# Stack complÃ¨te
docker-compose -f docker-compose.research.yml up -d

# Validation
poetry run python scripts/validate_installation.py
```

## Integration Layer

```python
from qframe.research.integration_layer import create_research_integration

integration = create_research_integration(use_minio=False)
status = integration.get_integration_status()
features = await integration.compute_research_features(data)
```

## Performance Analytics

```python
from qframe.research.backtesting import AdvancedPerformanceAnalyzer

analyzer = AdvancedPerformanceAnalyzer()
analysis = analyzer.analyze_comprehensive(backtest_result)

# MÃ©triques avancÃ©es : Sortino, Calmar, VaR/CVaR, Skewness, Kurtosis
# Rolling metrics, Drawdown analysis, Confidence intervals
```

## Voir aussi

- [Data Lake](data-lake.md) - Storage et catalog
- [Distributed Computing](distributed.md) - Dask et Ray
- [MLOps Pipeline](mlops.md) - Experiment tracking