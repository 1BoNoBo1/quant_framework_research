"""
DMN LSTM Trainer - Composant pour l'entra√Ænement de mod√®les LSTM
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import json

class DMNLSTMTrainer:
    """Interface pour l'entra√Ænement de mod√®les Deep Market Networks LSTM."""

    def __init__(self):
        self.model_config = {}
        self.training_history = []
        self.current_model = None

    def render_model_config(self):
        """Rendu de la configuration du mod√®le LSTM."""
        st.subheader("üß¨ LSTM Model Configuration")

        with st.expander("Architecture Settings", expanded=True):
            col1, col2, col3 = st.columns(3)

            with col1:
                architecture_config = {
                    'window_size': st.slider(
                        "Sequence Length",
                        min_value=10,
                        max_value=200,
                        value=64,
                        help="Taille de la s√©quence d'entr√©e"
                    ),
                    'hidden_size': st.selectbox(
                        "Hidden Size",
                        [32, 64, 128, 256, 512],
                        index=1,
                        help="Taille des couches cach√©es"
                    ),
                    'num_layers': st.slider(
                        "Number of Layers",
                        min_value=1,
                        max_value=5,
                        value=2
                    )
                }

            with col2:
                regularization_config = {
                    'dropout': st.slider(
                        "Dropout Rate",
                        min_value=0.0,
                        max_value=0.5,
                        value=0.2,
                        step=0.05
                    ),
                    'use_attention': st.checkbox(
                        "Attention Mechanism",
                        value=True,
                        help="Activer le m√©canisme d'attention"
                    ),
                    'bidirectional': st.checkbox(
                        "Bidirectional LSTM",
                        value=False
                    )
                }

            with col3:
                training_config = {
                    'optimizer': st.selectbox(
                        "Optimizer",
                        ["Adam", "SGD", "RMSprop", "AdamW"],
                        help="Optimiseur pour l'entra√Ænement"
                    ),
                    'learning_rate': st.number_input(
                        "Learning Rate",
                        min_value=0.0001,
                        max_value=0.1,
                        value=0.001,
                        format="%.4f"
                    ),
                    'batch_size': st.selectbox(
                        "Batch Size",
                        [16, 32, 64, 128, 256],
                        index=2
                    )
                }

        # Configuration des donn√©es
        with st.expander("Data Configuration"):
            col_data1, col_data2 = st.columns(2)

            with col_data1:
                data_config = {
                    'symbols': st.multiselect(
                        "Trading Symbols",
                        ["BTC/USDT", "ETH/USDT", "BNB/USDT", "SOL/USDT", "ADA/USDT"],
                        default=["BTC/USDT"],
                        help="Symboles pour l'entra√Ænement"
                    ),
                    'timeframe': st.selectbox(
                        "Timeframe",
                        ["1m", "5m", "15m", "1h", "4h", "1d"],
                        index=3
                    ),
                    'lookback_periods': st.number_input(
                        "Lookback Periods",
                        min_value=100,
                        max_value=10000,
                        value=1000
                    )
                }

            with col_data2:
                split_config = {
                    'train_split': st.slider(
                        "Train Split",
                        min_value=0.6,
                        max_value=0.9,
                        value=0.8
                    ),
                    'validation_split': st.slider(
                        "Validation Split",
                        min_value=0.1,
                        max_value=0.3,
                        value=0.2
                    ),
                    'test_split': st.slider(
                        "Test Split",
                        min_value=0.05,
                        max_value=0.3,
                        value=0.1
                    )
                }

        return {**architecture_config, **regularization_config, **training_config, **data_config, **split_config}

    def render_training_controls(self):
        """Rendu des contr√¥les d'entra√Ænement."""
        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            epochs = st.number_input(
                "Epochs",
                min_value=1,
                max_value=1000,
                value=100,
                help="Nombre d'√©poques d'entra√Ænement"
            )

        with col2:
            start_training = st.button("üöÄ Start Training", type="primary", use_container_width=True)

        with col3:
            pause_training = st.button("‚è∏Ô∏è Pause", use_container_width=True)

        with col4:
            save_model = st.button("üíæ Save Model", use_container_width=True)

        with col5:
            load_model = st.button("üìÅ Load Model", use_container_width=True)

        # Actions
        if start_training:
            st.session_state['lstm_training'] = True
            st.session_state['lstm_start_time'] = datetime.now()
            st.session_state['lstm_epochs'] = epochs
            return "start"
        elif pause_training:
            st.session_state['lstm_training'] = False
            return "pause"
        elif save_model:
            return "save"
        elif load_model:
            return "load"

        return None

    def render_training_progress(self):
        """Rendu du progr√®s d'entra√Ænement."""
        if not st.session_state.get('lstm_training', False):
            st.info("No training in progress")
            return

        st.subheader("üìä Training Progress")

        # M√©triques simul√©es
        current_epoch = np.random.randint(1, 100)
        total_epochs = st.session_state.get('lstm_epochs', 100)
        train_loss = np.random.uniform(0.01, 0.1)
        val_loss = np.random.uniform(0.02, 0.12)
        accuracy = np.random.uniform(0.7, 0.95)
        time_per_epoch = np.random.uniform(0.8, 2.0)

        # M√©triques principales
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Epoch", f"{current_epoch}/{total_epochs}")
        with col2:
            st.metric("Train Loss", f"{train_loss:.4f}", f"-{train_loss*0.1:.4f}")
        with col3:
            st.metric("Val Loss", f"{val_loss:.4f}", f"-{val_loss*0.05:.4f}")
        with col4:
            st.metric("Accuracy", f"{accuracy:.1%}", f"+{accuracy*0.01:.1%}")
        with col5:
            st.metric("Time/Epoch", f"{time_per_epoch:.1f}s")

        # Progress bar
        progress = current_epoch / total_epochs
        st.progress(progress)

        # Graphiques de training
        self._render_training_charts(current_epoch)

    def _render_training_charts(self, current_epoch: int):
        """Rendu des graphiques de training."""
        # Donn√©es simul√©es
        epochs = list(range(1, current_epoch + 1))
        train_losses = np.exp(-np.linspace(2, 4, current_epoch)) + np.random.randn(current_epoch) * 0.01
        val_losses = np.exp(-np.linspace(1.8, 3.5, current_epoch)) + np.random.randn(current_epoch) * 0.02
        accuracies = 1 - np.exp(-np.linspace(1, 3, current_epoch)) + np.random.randn(current_epoch) * 0.02

        # Graphique des losses
        col_chart1, col_chart2 = st.columns(2)

        with col_chart1:
            fig_loss = go.Figure()
            fig_loss.add_trace(go.Scatter(
                x=epochs,
                y=train_losses,
                mode='lines',
                name='Training Loss',
                line=dict(color='#00ff88', width=2)
            ))
            fig_loss.add_trace(go.Scatter(
                x=epochs,
                y=val_losses,
                mode='lines',
                name='Validation Loss',
                line=dict(color='#ff6b6b', width=2)
            ))

            fig_loss.update_layout(
                title="Training & Validation Loss",
                xaxis_title="Epoch",
                yaxis_title="Loss",
                template='plotly_dark',
                height=350
            )

            st.plotly_chart(fig_loss, use_container_width=True)

        with col_chart2:
            fig_acc = go.Figure()
            fig_acc.add_trace(go.Scatter(
                x=epochs,
                y=accuracies,
                mode='lines',
                name='Accuracy',
                line=dict(color='#6b88ff', width=2),
                fill='tonexty'
            ))

            fig_acc.update_layout(
                title="Model Accuracy",
                xaxis_title="Epoch",
                yaxis_title="Accuracy",
                template='plotly_dark',
                height=350
            )

            st.plotly_chart(fig_acc, use_container_width=True)

    def render_model_predictions(self):
        """Rendu des pr√©dictions du mod√®le."""
        st.subheader("üìà Model Predictions")

        # Donn√©es simul√©es de pr√©dictions
        dates = pd.date_range(start='2024-01-01', periods=100, freq='H')
        actual_prices = 50000 + np.cumsum(np.random.randn(100) * 100)
        predicted_prices = actual_prices + np.random.randn(100) * 50

        # Graphique pr√©dictions vs r√©alit√©
        fig = go.Figure()

        fig.add_trace(go.Scatter(
            x=dates,
            y=actual_prices,
            mode='lines',
            name='Actual Price',
            line=dict(color='#00ff88', width=2)
        ))

        fig.add_trace(go.Scatter(
            x=dates,
            y=predicted_prices,
            mode='lines',
            name='Predicted Price',
            line=dict(color='#ff6b6b', width=2, dash='dash')
        ))

        # Zone d'erreur
        upper_bound = predicted_prices + np.abs(actual_prices - predicted_prices)
        lower_bound = predicted_prices - np.abs(actual_prices - predicted_prices)

        fig.add_trace(go.Scatter(
            x=dates,
            y=upper_bound,
            fill=None,
            mode='lines',
            line_color='rgba(0,0,0,0)',
            showlegend=False
        ))

        fig.add_trace(go.Scatter(
            x=dates,
            y=lower_bound,
            fill='tonexty',
            mode='lines',
            line_color='rgba(0,0,0,0)',
            name='Prediction Interval',
            fillcolor='rgba(255, 107, 107, 0.1)'
        ))

        fig.update_layout(
            title="LSTM Predictions vs Actual Prices",
            xaxis_title="Time",
            yaxis_title="Price (USDT)",
            template='plotly_dark',
            height=400,
            hovermode='x unified'
        )

        st.plotly_chart(fig, use_container_width=True)

        # M√©triques de performance
        self._render_prediction_metrics(actual_prices, predicted_prices)

    def _render_prediction_metrics(self, actual: np.ndarray, predicted: np.ndarray):
        """Rendu des m√©triques de pr√©diction."""
        # Calcul des m√©triques
        mse = np.mean((actual - predicted) ** 2)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(actual - predicted))
        r2 = 1 - (np.sum((actual - predicted) ** 2) / np.sum((actual - np.mean(actual)) ** 2))

        # Direction accuracy
        actual_direction = np.sign(np.diff(actual))
        predicted_direction = np.sign(np.diff(predicted))
        direction_accuracy = np.mean(actual_direction == predicted_direction)

        # Affichage des m√©triques
        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            st.metric("R¬≤ Score", f"{r2:.4f}")
        with col2:
            st.metric("RMSE", f"{rmse:.2f}")
        with col3:
            st.metric("MAE", f"{mae:.2f}")
        with col4:
            st.metric("Direction Accuracy", f"{direction_accuracy:.1%}")
        with col5:
            st.metric("MSE", f"{mse:.2f}")

    def render_feature_importance(self):
        """Rendu de l'importance des features."""
        st.subheader("üîç Feature Importance")

        # Features simul√©es
        features = ['open', 'high', 'low', 'close', 'volume', 'vwap', 'rsi', 'macd', 'bb_upper', 'bb_lower']
        importance_scores = np.random.uniform(0.05, 0.25, len(features))
        importance_scores = importance_scores / importance_scores.sum()  # Normaliser

        # Cr√©er DataFrame
        importance_df = pd.DataFrame({
            'Feature': features,
            'Importance': importance_scores
        }).sort_values('Importance', ascending=True)

        # Graphique en barres horizontales
        fig = px.bar(
            importance_df,
            x='Importance',
            y='Feature',
            orientation='h',
            title='Feature Importance in LSTM Model',
            color='Importance',
            color_continuous_scale='Viridis'
        )

        fig.update_layout(
            template='plotly_dark',
            height=400,
            showlegend=False
        )

        st.plotly_chart(fig, use_container_width=True)

    def render_model_architecture(self, config: Dict):
        """Rendu de l'architecture du mod√®le."""
        st.subheader("üèóÔ∏è Model Architecture")

        # Visualisation de l'architecture
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### Architecture Summary")
            st.json({
                "Input Shape": f"({config.get('batch_size', 64)}, {config.get('window_size', 64)}, features)",
                "LSTM Layers": config.get('num_layers', 2),
                "Hidden Size": config.get('hidden_size', 128),
                "Dropout": config.get('dropout', 0.2),
                "Attention": config.get('use_attention', True),
                "Bidirectional": config.get('bidirectional', False),
                "Output Shape": "(batch_size, 1)"
            })

        with col2:
            st.markdown("### Training Parameters")
            st.json({
                "Optimizer": config.get('optimizer', 'Adam'),
                "Learning Rate": config.get('learning_rate', 0.001),
                "Batch Size": config.get('batch_size', 64),
                "Sequence Length": config.get('window_size', 64),
                "Loss Function": "MSE",
                "Metrics": ["MAE", "R¬≤", "Direction Accuracy"]
            })

    def render_model_comparison(self):
        """Rendu de la comparaison de mod√®les."""
        st.subheader("üèÜ Model Comparison")

        # Donn√©es simul√©es de diff√©rents mod√®les
        models_data = pd.DataFrame({
            'Model': ['LSTM_v1.0', 'LSTM_v1.1', 'LSTM_v2.0', 'BiLSTM_v1.0', 'LSTM+Attention'],
            'R¬≤': [0.7234, 0.7456, 0.7823, 0.7634, 0.8156],
            'RMSE': [45.2, 42.8, 38.9, 41.2, 35.4],
            'Direction Acc': [0.732, 0.745, 0.789, 0.756, 0.812],
            'Training Time': ['12m', '15m', '18m', '22m', '25m'],
            'Parameters': ['1.2M', '1.8M', '2.3M', '2.4M', '3.1M']
        })

        # Tableau interactif
        st.dataframe(
            models_data,
            use_container_width=True,
            hide_index=True,
            column_config={
                "R¬≤": st.column_config.ProgressColumn(
                    "R¬≤ Score",
                    help="Coefficient de d√©termination",
                    min_value=0,
                    max_value=1,
                ),
                "Direction Acc": st.column_config.ProgressColumn(
                    "Direction Accuracy",
                    help="Pr√©cision de pr√©diction de direction",
                    min_value=0,
                    max_value=1,
                ),
            }
        )

        # Graphiques de comparaison
        col_comp1, col_comp2 = st.columns(2)

        with col_comp1:
            fig_r2 = px.bar(
                models_data,
                x='Model',
                y='R¬≤',
                title='R¬≤ Score Comparison',
                color='R¬≤',
                color_continuous_scale='Viridis'
            )
            fig_r2.update_layout(template='plotly_dark', height=350)
            st.plotly_chart(fig_r2, use_container_width=True)

        with col_comp2:
            fig_scatter = px.scatter(
                models_data,
                x='RMSE',
                y='Direction Acc',
                size='R¬≤',
                color='Model',
                title='Performance Trade-off',
                hover_data=['Parameters']
            )
            fig_scatter.update_layout(template='plotly_dark', height=350)
            st.plotly_chart(fig_scatter, use_container_width=True)

    def get_training_status(self):
        """Retourne le statut actuel de l'entra√Ænement."""
        if not st.session_state.get('lstm_training', False):
            return None

        start_time = st.session_state.get('lstm_start_time')
        if not start_time:
            return None

        elapsed = datetime.now() - start_time
        total_epochs = st.session_state.get('lstm_epochs', 100)
        current_epoch = min(int(elapsed.total_seconds() / 2), total_epochs)  # Simulation

        return {
            'status': 'Training' if current_epoch < total_epochs else 'Completed',
            'current_epoch': current_epoch,
            'total_epochs': total_epochs,
            'elapsed_time': elapsed,
            'progress': current_epoch / total_epochs
        }